## 1.3 Types of Machine Learning

Machine learning encompasses a variety of approaches and techniques, each suited to different types of problems and data. The three main types of machine learning are supervised learning, unsupervised learning, and reinforcement learning. Each type offers unique strengths and applications, making machine learning a versatile tool for solving complex problems.

### Supervised Learning

Supervised learning is one of the most widely used and studied types of machine learning. In supervised learning, the algorithm is trained on a labeled dataset, which means that each training example is paired with an output label. The goal of the algorithm is to learn a mapping from inputs to outputs that can be used to make predictions on new, unseen data.

**Definition**: Supervised learning involves learning from labeled data to make predictions. The algorithm learns from a set of training data where the input-output pairs are known, and it uses this information to predict the output for new data points.

**Examples**: 

- **Classification**: This task involves predicting a categorical label for a given input. For example, spam detection in email systems is a classification problem. The algorithm is trained on a dataset of emails labeled as "spam" or "not spam." Once trained, the model can classify new emails into these categories.

- **Regression**: This task involves predicting a continuous value for a given input. Our motivating problem of predicting housing prices is a regression problem. The algorithm learns from historical data of house features and their corresponding sale prices to predict the price of new houses.

To illustrate supervised learning, let's return to our housing price prediction example. Suppose we have a dataset where each house is represented by a set of features, such as the number of bedrooms, square footage, location, and age. Each house also has a known sale price, which serves as the label.

In mathematical terms, let $X$ represent the features of the houses and $y$ represent the sale prices. Our dataset consists of pairs $(X_i, y_i)$, where $X_i$ is the feature vector for house $i$ and $y_i$ is the corresponding sale price. The goal of supervised learning is to find a function $f$ that maps $X$ to $y$:

$$ y = f(X) $$

One common approach to supervised learning is to use linear regression, which assumes that the relationship between the features and the target variable is linear. As discussed earlier, the linear regression model can be expressed as:

$$ y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \cdots + \beta_n x_n + \epsilon $$

where $\beta_0$ is the intercept, $\beta_1, \beta_2, \ldots, \beta_n$ are the coefficients, and $\epsilon$ is the error term.

During training, the algorithm estimates the values of the coefficients $\beta$ by minimizing the difference between the predicted and actual sale prices. This process is known as "fitting" the model to the data. Once the model is trained, it can be used to predict the sale price of new houses based on their features.

Supervised learning algorithms can be more complex than linear regression. For example, decision trees and support vector machines are popular supervised learning algorithms that can model more complex relationships between features and target variables. Decision trees partition the feature space into regions with similar target values, while support vector machines find the optimal boundary that separates different classes in the data.

Despite their differences, all supervised learning algorithms share the common goal of learning from labeled data to make accurate predictions on new data. By leveraging the information in the training data, these algorithms can generalize to new situations and provide valuable insights and predictions.

In the next section, we will explore unsupervised learning, another important type of machine learning that deals with unlabeled data and seeks to uncover hidden patterns and structures.
